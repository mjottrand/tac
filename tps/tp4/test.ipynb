{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4eb232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "987 fichiers chargés dans le corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thème 1: britannique, congo, nations, congrès, bretagne, cabinet, budget, art, prince, soviétique\n",
      "\n",
      "Thème 2: dc, el, lo, ct, da, mme, id, no, musique, ch\n",
      "\n",
      "Thème 3: milliards, travailleurs, dollars, banque, congo, augmentation, grève, entreprises, bretagne, salaires\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Paramètres\n",
    "# -------------------------------\n",
    "data_path = \"../../data/txt/\"  # chemin vers ton corpus\n",
    "n_topics = 3  # nombre de thèmes à extraire\n",
    "n_top_words = 10  # nombre de mots par thème\n",
    "passes = 10  # nombre de passes d'apprentissage sur le corpus\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Chargement du corpus\n",
    "# -------------------------------\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f.endswith(\".txt\")]\n",
    "texts = [open(os.path.join(data_path, f), \"r\", encoding=\"utf-8\").read() for f in files]\n",
    "print(f\"{len(files)} fichiers chargés dans le corpus\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Prétraitement : tokenisation + suppression stopwords\n",
    "# -------------------------------\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"plus\", \"cette\", \"être\", \"tout\", \"fait\", \"comme\", \"leurs\", \"deux\",\n",
    "\"bien\", \"après\", \"sans\", \"dont\", \"tous\", \"encore\", \"faire\", \"peut\",\n",
    "\"aussi\", \"ceux\", \"elles\", \"alors\", \"toujours\", \"devant\",\n",
    "\"également\", \"aujourd\", \"dernier\", \"première\", \"nouvelle\", \"certains\",\n",
    "\"quatre\", \"trop\", \"dès\", \"quand\", \"notamment\", \"cependant\", \"jamais\",\n",
    "\"ici\", \"beaucoup\", \"ensuite\", \"assez\", \"puis\", \"laquelle\", \"chaque\",\n",
    "\"seulement\", \"entre\", \"sous\", \"dit\", \"autres\", \"très\", \"autre\",\n",
    "\"ans\", \"ainsi\", \"peu\", \"non\", \"depuis\", \"avoir\", \"moins\", \"toute\",\n",
    "\"trois\", \"toutes\", \"quelques\", \"faut\", \"cet\", \"celui\", \"doit\", \"jusqu\",\n",
    "\"vie\", \"déjà\", \"celle\", \"vers\", \"dire\", \"cela\", \"fois\", \"donc\",\n",
    "\"pendant\", \"année\", \"cours\", \"grande\", \"grand\", \"part\", \"rue\", \"avant\", \n",
    "\"mois\", \"van\", \"jour\", \"heures\", \"point\", \"situation\", \"question\", \"soir\", \n",
    "\"nouveau\", \"fin\", \"hui\", \"jours\", \"suite\", \"vue\", \"ville\", \"car\", \"moment\", \n",
    "\"place\", \"compte\", \"voir\", \"cas\", \"rien\", \"effet\", \"matin\", \"ailleurs\", \n",
    "\"plusieurs\", \"vient\", \"partie\", \"saint\", \"chez\", \"janvier\", \"près\", \n",
    "\"générale\", \"mardi\", \"dimanche\", \"lundi\", \"mars\", \"décembre\", \"octobre\", \n",
    "\"tant\", \"reste\", \"ment\", \"bon\", \"fort\", \"pris\", \"maison\", \"jeudi\", \"nom\", \n",
    "\"temps\", \"lieu\", \"homme\", \"problème\", \"hommes\", \"midi\", \"heure\", \"parce\",\n",
    "\"raison\", \"cinq\", \"nord\", \"œuvre\", \"années\", \"avril\", \"semaine\",\n",
    "\"pourrait\", \"juin\", \"selon\", \"novembre\", \"donné\", \"bas\", \"porte\", \"prendre\", \n",
    "\"quelque\", \"enfin\",  \"nombre\",\"actuellement\", \"dernière\", \"enfants\", \n",
    "\"vendredi\", \"mis\",\"aucun\",\"bonne\", \"presse\", \"mercredi\", \"parmi\",\"enfin\",  \n",
    "\"juillet\", \"samedi\", \"journal\",\"quelque\", \"dun\", \"dune\", \"c'est\", \"cest\", \n",
    "\"qu'il\", \"quil\", \"faire\", \"ans\", \"heures\", \"grands\", \"pays\", \"plus\", \"quils\", \n",
    "\"grande\",\"fut\", \"fin\", \"faire\", \"part\", \"ministres\", \"ministre\", \"gouvernement\", \n",
    "\"belgique\", \"bruxelles\", \"France\", \"Paris\", \"général\", \"prix\", \"politique\", \"économique\"]\n",
    "sw = sw = list(set(sw))\n",
    "\n",
    "def preprocess(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in sw]\n",
    "\n",
    "processed_texts = [preprocess(t) for t in texts]\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Création du dictionnaire et du corpus\n",
    "# -------------------------------\n",
    "dictionary = Dictionary(processed_texts)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)  # filtre mots trop rares ou trop fréquents\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "\n",
    "# -------------------------------\n",
    "# 5️⃣ LDA avec LdaModel\n",
    "# -------------------------------\n",
    "lda = LdaModel(corpus=corpus,\n",
    "               num_topics=n_topics,\n",
    "               id2word=dictionary,\n",
    "               passes=passes,\n",
    "               random_state=42)\n",
    "\n",
    "# -------------------------------\n",
    "# 6️⃣ Affichage des thèmes\n",
    "# -------------------------------\n",
    "for topic_idx, topic in lda.show_topics(formatted=False, num_words=n_top_words):\n",
    "    top_words = [word for word, prob in topic]\n",
    "    print(f\"\\nThème {topic_idx + 1}: {', '.join(top_words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b04aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thème 1 (Disours potentiel) : exposition, britannique, allemands, février, cabinet, prince, berlin, bretagne, office, allemande, reine, sécurité, nations, famille, gauche, espagne, italie, américaine, sir, droits\n",
      "\n",
      "Thème 2 (Disours potentiel) : bretagne, salaires, travailleurs, congo, britannique, dollars, chômage, américain, février, charbon, américaine, tonnes, socialistes, exportations, troupes, marshall, américains, communistes, région, dépenses\n",
      "\n",
      "Thème 3 (Disours potentiel) : art, père, mme, prince, œuvres, exposition, théâtre, famille, comte, concours, cœur, province, mère, fils, siècle, auteur, fille, belle, beau, air\n",
      "\n",
      "Thème 4 (Disours potentiel) : travailleurs, lutte, actions, chômage, capitalistes, congo, milliards, commun, socialiste, fonds, socialistes, budget, gagné, capital, bretagne, ouvrière, construction, victoire, maladie, dette\n",
      "\n",
      "Thème 5 (Disours potentiel) : congo, liste, lot, témoin, mission, albert, revenus, budget, développement, augmentation, publics, prince, entreprises, reine, section, petits, agriculture, accusé, moyennes, argentine\n",
      "\n",
      "Thème 6 (Disours potentiel) : kil, opium, accusé, robe, oui, prince, chine, colonat, rang, rangs, femmes, esl, balles, autriche, social, encolure, mère, palestine, hausse, faites\n",
      "\n",
      "Thème 7 (Disours potentiel) : mme, musique, monsieur, madame, orchestre, août, concert, belle, vente, art, septembre, théâtre, meuse, joseph, fille, beau, sport, suisse, gand, bois\n",
      "\n",
      "Thème 8 (Disours potentiel) : congrès, reine, socialiste, quo, lettre, rome, prince, socialistes, dea, italie, berlin, proposition, cardinaux, celte, esl, catholiques, chemins, charbon, fourmis, employés\n",
      "\n",
      "Thème 9 (Disours potentiel) : congo, travailleurs, milliards, budget, septembre, socialistes, mme, soviétique, août, bretagne, augmentation, dollars, fonds, luxembourg, troupes, congrès, banque, communistes, février, œuvres\n",
      "\n",
      "Thème 10 (Disours potentiel) : idem, marshall, art, emulation, agriculture, agricole, juil, royale, professeur, hollande, août, dépenses, idée, chemin, varsovie, italie, budget, congrès, nation, chemins\n",
      "\n",
      "Thème 11 (Disours potentiel) : travailleurs, communiste, congo, grève, pro, com, communistes, lutte, socialistes, socialiste, soviétique, tre, res, milliards, ouvrière, eyskens, unique, social, tions, oui\n",
      "\n",
      "Thème 12 (Disours potentiel) : travailleurs, grève, communiste, borinage, livre, socialistes, chômage, étrangers, mineurs, socialiste, usines, franco, frontaliers, livres, bretagne, chrétiens, région, com, britannique, élections\n",
      "\n",
      "Thème 13 (Disours potentiel) : travailleurs, soviétique, dollars, février, congo, province, cabinet, milliards, américains, congrès, hausse, août, déclaration, septembre, banque, art, américain, socialiste, justice, sécurité\n",
      "\n",
      "Thème 14 (Disours potentiel) : charleroi, idem, congo, frs, mme, namur, katanga, vol, travailleurs, cap, lea, com, art, famille, louis, gand, bel, col, communiste, belg\n",
      "\n",
      "Thème 15 (Disours potentiel) : banque, février, août, congo, actions, capital, septembre, clôture, venant, tonnes, ventes, exercice, cap, titres, franc, tendance, mines, dollars, dividende, comptant\n",
      "\n",
      "Thème 16 (Disours potentiel) : dewez, accusé, victime, bertrand, haye, christiane, section, mari, congo, christian, reine, audience, épouse, langue, souveraine, école, commun, idée, intention, seconde\n",
      "\n",
      "Thème 17 (Disours potentiel) : bretagne, britannique, budget, soviétique, nations, déclaration, communistes, milliards, washington, congo, américains, sécurité, américain, européenne, spaak, dollars, ouest, américaine, août, reuter\n",
      "\n",
      "Thème 18 (Disours potentiel) : tél, ena, opel, voitures, moteur, renault, luxe, ford, fiat, voiture, neuf, taunus, peugeot, crédit, namur, cheminots, radio, garantie, chevrolet, citroen\n",
      "\n",
      "Thème 19 (Disours potentiel) : auto, voiture, septembre, musique, section, georges, hôpital, mme, princesse, soviétique, liste, habitant, collision, enfant, marie, avenue, charles, bretagne, accident, travailleurs\n",
      "\n",
      "Thème 20 (Disours potentiel) : banque, milliards, valeurs, taux, bourse, dollars, actions, hausse, fonds, entreprises, crédit, sociétés, augmentation, baisse, investissements, capitaux, banques, monétaire, niveau, obligations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel # Utilisation du modèle natif plus stable\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Paramètres (Ajustés selon les sources)\n",
    "# -------------------------------\n",
    "data_path = \"../../data/txt/\" \n",
    "# Les sources recommandent 280 thèmes pour une analyse fine [3]\n",
    "n_topics = 20 # Augmentez à 280 si vous avez un gros corpus\n",
    "n_top_words = 20 # Standard utilisé par les auteurs [6]\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Chargement et Prétraitement\n",
    "# -------------------------------\n",
    "# Téléchargement des ressources françaises\n",
    "nltk.download('stopwords')\n",
    "# CRUCIAL : Utiliser le français pour l'Encyclopédie [1]\n",
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"plus\", \"cette\", \"être\", \"tout\", \"fait\", \"comme\", \"leurs\", \"deux\",\n",
    "\"bien\", \"après\", \"sans\", \"dont\", \"tous\", \"encore\", \"faire\", \"peut\",\n",
    "\"aussi\", \"ceux\", \"elles\", \"alors\", \"toujours\", \"devant\",\n",
    "\"également\", \"aujourd\", \"dernier\", \"première\", \"nouvelle\", \"certains\",\n",
    "\"quatre\", \"trop\", \"dès\", \"quand\", \"notamment\", \"cependant\", \"jamais\",\n",
    "\"ici\", \"beaucoup\", \"ensuite\", \"assez\", \"puis\", \"laquelle\", \"chaque\",\n",
    "\"seulement\", \"entre\", \"sous\", \"dit\", \"autres\", \"très\", \"autre\",\n",
    "\"ans\", \"ainsi\", \"peu\", \"non\", \"depuis\", \"avoir\", \"moins\", \"toute\",\n",
    "\"trois\", \"toutes\", \"quelques\", \"faut\", \"cet\", \"celui\", \"doit\", \"jusqu\",\n",
    "\"vie\", \"déjà\", \"celle\", \"vers\", \"dire\", \"cela\", \"fois\", \"donc\",\n",
    "\"pendant\", \"année\", \"cours\", \"grande\", \"grand\", \"part\", \"rue\", \"avant\", \n",
    "\"mois\", \"van\", \"jour\", \"heures\", \"point\", \"situation\", \"question\", \"soir\", \n",
    "\"nouveau\", \"fin\", \"hui\", \"jours\", \"suite\", \"vue\", \"ville\", \"car\", \"moment\", \n",
    "\"place\", \"compte\", \"voir\", \"cas\", \"rien\", \"effet\", \"matin\", \"ailleurs\", \n",
    "\"plusieurs\", \"vient\", \"partie\", \"saint\", \"chez\", \"janvier\", \"près\", \n",
    "\"générale\", \"mardi\", \"dimanche\", \"lundi\", \"mars\", \"décembre\", \"octobre\", \n",
    "\"tant\", \"reste\", \"ment\", \"bon\", \"fort\", \"pris\", \"maison\", \"jeudi\", \"nom\", \n",
    "\"temps\", \"lieu\", \"homme\", \"problème\", \"hommes\", \"midi\", \"heure\", \"parce\",\n",
    "\"raison\", \"cinq\", \"nord\", \"œuvre\", \"années\", \"avril\", \"semaine\",\n",
    "\"pourrait\", \"juin\", \"selon\", \"novembre\", \"donné\", \"bas\", \"porte\", \"prendre\", \n",
    "\"quelque\", \"enfin\",  \"nombre\",\"actuellement\", \"dernière\", \"enfants\", \n",
    "\"vendredi\", \"mis\",\"aucun\",\"bonne\", \"presse\", \"mercredi\", \"parmi\",\"enfin\",  \n",
    "\"juillet\", \"samedi\", \"journal\",\"quelque\", \"dun\", \"dune\", \"c'est\", \"cest\", \n",
    "\"qu'il\", \"quil\", \"faire\", \"ans\", \"heures\", \"grands\", \"pays\", \"plus\", \"quils\", \n",
    "\"grande\",\"fut\", \"fin\", \"faire\", \"part\", \"ministres\", \"ministre\", \"gouvernement\", \n",
    "\"belgique\", \"bruxelles\", \"France\", \"Paris\", \"général\", \"prix\", \"politique\", \"économique\"]\n",
    "sw = sw = list(set(sw))\n",
    "\n",
    "def preprocess(text):\n",
    "    # Les auteurs recommandent de filtrer les mots fonctionnels [3]\n",
    "    return [token for token in simple_preprocess(text) if token not in sw and len(token) > 2]\n",
    "\n",
    "# Chargement (gestion des erreurs d'encodage fréquente sur les textes anciens)\n",
    "texts = []\n",
    "for f in sorted(os.listdir(data_path)):\n",
    "    if f.endswith(\".txt\"):\n",
    "        with open(os.path.join(data_path, f), \"r\", encoding=\"utf-8\", errors='ignore') as file:\n",
    "            texts.append(preprocess(file.read()))\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Création du dictionnaire et du modèle\n",
    "# -------------------------------\n",
    "dictionary = Dictionary(texts)\n",
    "# Filtrage : les auteurs excluent les mots trop fréquents ou rares [9]\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Entraînement du modèle LDA\n",
    "lda = LdaModel(corpus=corpus, num_topics=n_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Affichage (comparable aux Tables 1 & 2 des sources)\n",
    "# -------------------------------\n",
    "for topic_idx in range(n_topics):\n",
    "    # Récupération des 20 mots-clés [6]\n",
    "    words = lda.show_topic(topic_idx, topn=n_top_words)\n",
    "    topic_words = [word for word, prob in words]\n",
    "    print(f\"\\nThème {topic_idx + 1} (Disours potentiel) : {', '.join(topic_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9275c6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du corpus...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle avec 10 thèmes...\n",
      "\n",
      "Thème 1 : seul, autant, con, hier, nombreux, semble, mouvement, petit, services, succès, réunion, nouveaux, dix, abord, milieux, occasion, début, ouvriers, six, doute\n",
      "\n",
      "Thème 2 : doute, dix, aucune, donner, semble, cent, sud, etc, banque, occasion, seul, six, côté, mai, août, sait, réunion, agit, doivent, nombreux\n",
      "\n",
      "Thème 3 : britannique, aucune, dix, août, mal, sait, mouvement, septembre, reçu, sud, force, austérité, mettre, semble, agit, con, coup, ouvriers, bureau, économiques\n",
      "\n",
      "Thème 4 : six, banque, donner, aucune, administration, certaines, directeur, britannique, jean, congrès, pourquoi, conditions, dollars, jeune, force, hier, cour, coup, doute, française\n",
      "\n",
      "Thème 5 : seul, semble, août, etc, voici, ministère, tour, bureau, jeune, surtout, mal, présence, sud, groupe, réunion, voix, mouvement, aide, façon, sens\n",
      "\n",
      "Thème 6 : banque, esprit, donner, occasion, hier, congrès, septembre, possible, sécurité, etc, avis, services, mme, aucune, nombreux, déclaration, sud, période, ensemble, doivent\n",
      "\n",
      "Thème 7 : conditions, française, doute, mal, bureau, mai, mettre, coup, dollars, anglais, salle, angleterre, police, moyen, donner, britannique, produits, cent, seule, organisation\n",
      "\n",
      "Thème 8 : con, mai, sens, aucune, public, ouvriers, jeune, surtout, maintenant, septembre, côté, reçu, affaire, anglais, mieux, conditions, ensemble, certaines, semble, seul\n",
      "\n",
      "Thème 9 : banque, étrangères, réunion, ensemble, doivent, doute, dix, soviétique, française, con, agit, produits, surtout, peuvent, aucune, avis, force, août, mai, cent\n",
      "\n",
      "Thème 10 : ensemble, surtout, produits, groupe, britannique, septembre, tour, mal, angleterre, peuvent, congrès, mettre, esprit, jeunes, cour, personnes, services, force, succès, libre\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Paramètres basés sur les sources\n",
    "# -------------------------------\n",
    "# Les auteurs ont testé 280, 300, 330 et 360 thèmes [1].\n",
    "# Ils ont conclu que le modèle à 280 thèmes était le plus cohérent [2].\n",
    "n_topics = 10\n",
    "# L'analyse repose sur les 20 mots les plus significatifs par thème [2].\n",
    "n_top_words = 20 \n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Chargement et Prétraitement\n",
    "# -------------------------------\n",
    "# Chemin vers votre fichier spécifique\n",
    "file_path = \"../../data/tmp/corpus_clean2.txt\"\n",
    "\n",
    "# Les sources soulignent l'importance des noms (substantifs) [3].\n",
    "# Pour simplifier, nous utilisons ici une suppression rigoureuse des stopwords.\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"plus\", \"cette\", \"être\", \"tout\", \"fait\", \"comme\", \"leurs\", \"deux\",\n",
    "\"bien\", \"après\", \"sans\", \"dont\", \"tous\", \"encore\", \"faire\", \"peut\",\n",
    "\"aussi\", \"ceux\", \"elles\", \"alors\", \"toujours\", \"devant\",\n",
    "\"également\", \"aujourd\", \"dernier\", \"première\", \"nouvelle\", \"certains\",\n",
    "\"quatre\", \"trop\", \"dès\", \"quand\", \"notamment\", \"cependant\", \"jamais\",\n",
    "\"ici\", \"beaucoup\", \"ensuite\", \"assez\", \"puis\", \"laquelle\", \"chaque\",\n",
    "\"seulement\", \"entre\", \"sous\", \"dit\", \"autres\", \"très\", \"autre\",\n",
    "\"ans\", \"ainsi\", \"peu\", \"non\", \"depuis\", \"avoir\", \"moins\", \"toute\",\n",
    "\"trois\", \"toutes\", \"quelques\", \"faut\", \"cet\", \"celui\", \"doit\", \"jusqu\",\n",
    "\"vie\", \"déjà\", \"celle\", \"vers\", \"dire\", \"cela\", \"fois\", \"donc\",\n",
    "\"pendant\", \"année\", \"cours\", \"grande\", \"grand\", \"part\", \"rue\", \"avant\", \n",
    "\"mois\", \"van\", \"jour\", \"heures\", \"point\", \"situation\", \"question\", \"soir\", \n",
    "\"nouveau\", \"fin\", \"hui\", \"jours\", \"suite\", \"vue\", \"ville\", \"car\", \"moment\", \n",
    "\"place\", \"compte\", \"voir\", \"cas\", \"rien\", \"effet\", \"matin\", \"ailleurs\", \n",
    "\"plusieurs\", \"vient\", \"partie\", \"saint\", \"chez\", \"janvier\", \"près\", \n",
    "\"générale\", \"mardi\", \"dimanche\", \"lundi\", \"mars\", \"décembre\", \"octobre\", \n",
    "\"tant\", \"reste\", \"ment\", \"bon\", \"fort\", \"pris\", \"maison\", \"jeudi\", \"nom\", \n",
    "\"temps\", \"lieu\", \"homme\", \"problème\", \"hommes\", \"midi\", \"heure\", \"parce\",\n",
    "\"raison\", \"cinq\", \"nord\", \"œuvre\", \"années\", \"avril\", \"semaine\",\n",
    "\"pourrait\", \"juin\", \"selon\", \"novembre\", \"donné\", \"bas\", \"porte\", \"prendre\", \n",
    "\"quelque\", \"enfin\",  \"nombre\",\"actuellement\", \"dernière\", \"enfants\", \n",
    "\"vendredi\", \"mis\",\"aucun\",\"bonne\", \"presse\", \"mercredi\", \"parmi\",\"enfin\",  \n",
    "\"juillet\", \"samedi\", \"journal\",\"quelque\", \"dun\", \"dune\", \"c'est\", \"cest\", \n",
    "\"qu'il\", \"quil\", \"faire\", \"ans\", \"heures\", \"grands\", \"pays\", \"plus\", \"quils\", \n",
    "\"grande\",\"fut\", \"fin\", \"faire\", \"part\", \"ministres\", \"ministre\", \"gouvernement\", \n",
    "\"belgique\", \"bruxelles\", \"France\", \"Paris\", \"général\", \"prix\", \"politique\", \"économique\"]\n",
    "sw = sw = list(set(sw))\n",
    "\n",
    "def preprocess(text):\n",
    "    # Les auteurs filtrent les mots fonctionnels (stopwords) [1].\n",
    "    # Ils suggèrent de ne garder que les noms et noms propres [5].\n",
    "    tokens = simple_preprocess(text)\n",
    "    return [t for t in tokens if t not in sw and len(t) > 2]\n",
    "\n",
    "print(\"Chargement du corpus...\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    # On traite chaque ligne comme un article/document indépendant [6, 7].\n",
    "    processed_texts = [preprocess(line) for line in f]\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Création du modèle (LDA)\n",
    "# -------------------------------\n",
    "# Création du dictionnaire et du format \"Bag of Words\" (sac de mots) [8].\n",
    "dictionary = Dictionary(processed_texts)\n",
    "# Filtrage des mots trop rares ou trop fréquents comme dans PhiloMine [7].\n",
    "#dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "\n",
    "print(f\"Entraînement du modèle avec {n_topics} thèmes...\")\n",
    "# Bien que les auteurs utilisent MALLET [1], le modèle LdaModel \n",
    "# de Gensim est une alternative moderne produisant des résultats comparables.\n",
    "lda = LdaModel(corpus=corpus, num_topics=n_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Analyse des résultats\n",
    "# -------------------------------\n",
    "# Affichage des thèmes pour identifier les \"discours\" [2, 8].\n",
    "for topic_idx in range(n_topics):\n",
    "    words = lda.show_topic(topic_idx, topn=n_top_words)\n",
    "    topic_words = [word for word, prob in words]\n",
    "    print(f\"\\nThème {topic_idx + 1} : {', '.join(topic_words)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
