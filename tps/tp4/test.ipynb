{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4eb232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "987 fichiers chargés dans le corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thème 1: art, mme, el, dc, père, moi, ct, lo, famille, prince\n",
      "\n",
      "Thème 2: tél, da, ea, ena, lo, mme, travailleurs, dc, socialiste, socialistes\n",
      "\n",
      "Thème 3: milliards, congo, dc, dollars, bretagne, soviétique, travailleurs, britannique, décembre, banque\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Paramètres\n",
    "# -------------------------------\n",
    "data_path = \"../../data/txt/\"  # chemin vers ton corpus\n",
    "n_topics = 3  # nombre de thèmes à extraire\n",
    "n_top_words = 10  # nombre de mots par thème\n",
    "passes = 10  # nombre de passes d'apprentissage sur le corpus\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Chargement du corpus\n",
    "# -------------------------------\n",
    "files = [f for f in sorted(os.listdir(data_path)) if f.endswith(\".txt\")]\n",
    "texts = [open(os.path.join(data_path, f), \"r\", encoding=\"utf-8\").read() for f in files]\n",
    "print(f\"{len(files)} fichiers chargés dans le corpus\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Prétraitement : tokenisation + suppression stopwords\n",
    "# -------------------------------\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in stop_words]\n",
    "\n",
    "processed_texts = [preprocess(t) for t in texts]\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Création du dictionnaire et du corpus\n",
    "# -------------------------------\n",
    "dictionary = Dictionary(processed_texts)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)  # filtre mots trop rares ou trop fréquents\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "\n",
    "# -------------------------------\n",
    "# 5️⃣ LDA avec LdaModel\n",
    "# -------------------------------\n",
    "lda = LdaModel(corpus=corpus,\n",
    "               num_topics=n_topics,\n",
    "               id2word=dictionary,\n",
    "               passes=passes,\n",
    "               random_state=42)\n",
    "\n",
    "# -------------------------------\n",
    "# 6️⃣ Affichage des thèmes\n",
    "# -------------------------------\n",
    "for topic_idx, topic in lda.show_topics(formatted=False, num_words=n_top_words):\n",
    "    top_words = [word for word, prob in topic]\n",
    "    print(f\"\\nThème {topic_idx + 1}: {', '.join(top_words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b04aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thème 1 (Disours potentiel) : britannique, bretagne, soviétique, avril, nations, décembre, communistes, américain, américains, washington, américaine, juillet, ouest, congrès, berlin, communiste, déclaration, septembre, moscou, août\n",
      "\n",
      "Thème 2 (Disours potentiel) : milliards, banque, dollars, taux, valeurs, actions, hausse, fonds, bourse, entreprises, augmentation, crédit, sociétés, baisse, décembre, investissements, capitaux, juin, capital, niveau\n",
      "\n",
      "Thème 3 (Disours potentiel) : tél, charleroi, vente, vendre, décembre, beau, meubles, adresser, belle, bilan, cardinal, mme, ecr, adr, choix, louer, rossel, père, louis, fabrique\n",
      "\n",
      "Thème 4 (Disours potentiel) : sport, division, sieur, membre, daring, iii, ena, film, sortant, namur, aller, antwerp, gand, gantoise, tirlemont, standard, malines, charlerol, tournai, fléron\n",
      "\n",
      "Thème 5 (Disours potentiel) : esl, socialistes, reine, laurent, communistes, élait, élé, reuter, libéraux, cetle, tribunal, pré, sœur, new, york, discussion, renée, élections, procès, onze\n",
      "\n",
      "Thème 6 (Disours potentiel) : sir, stafford, tonnes, cripps, prisonniers, prince, commun, budget, américains, qualité, nations, anciens, division, avril, gaitskell, camions, gouverneur, bretagne, chancelier, yser\n",
      "\n",
      "Thème 7 (Disours potentiel) : one, mme, points, nin, namur, procureur, concours, meuse, bat, bin, tribunal, juin, lès, dinant, disques, dins, pus, madame, expert, ligne\n",
      "\n",
      "Thème 8 (Disours potentiel) : avril, milliards, juin, bretagne, août, dollars, congo, novembre, fonds, travailleurs, hausse, budget, art, crédit, militaires, augmentation, banque, tonnes, juillet, période\n",
      "\n",
      "Thème 9 (Disours potentiel) : soviétique, communistes, novembre, britannique, berlin, occidentale, américain, washington, reuter, cabinet, août, spaak, dévaluation, nankin, dollars, américains, communiste, acheson, ajouté, bretagne\n",
      "\n",
      "Thème 10 (Disours potentiel) : budget, art, famille, enseignement, concours, novembre, mme, théâtre, femmes, exposition, père, royale, œuvres, article, belle, petits, justice, mars, congo, école\n",
      "\n",
      "Thème 11 (Disours potentiel) : tél, moteur, voitures, luxe, opel, fiat, ford, voiture, taunus, peugeot, renault, garantie, crédit, salon, modèles, wavre, arrière, automobile, neuf, traction\n",
      "\n",
      "Thème 12 (Disours potentiel) : mars, avril, décembre, clôture, comptant, terme, juillet, février, bizerte, allemands, alliés, bourguiba, livre, sterling, aff, dea, américains, sante, dollars, américain\n",
      "\n",
      "Thème 13 (Disours potentiel) : congo, travailleurs, pro, com, lutte, ena, communiste, grève, socialiste, socialistes, tre, res, congolais, unique, eyskens, tions, ouvrier, milliards, république, soviétique\n",
      "\n",
      "Thème 14 (Disours potentiel) : mars, abbé, mme, arabes, décembre, curé, suisse, pâte, mlle, bernard, proposition, députés, nommé, bretagne, soc, jérusalem, sénat, vote, prince, juifs\n",
      "\n",
      "Thème 15 (Disours potentiel) : pension, namur, travailleurs, septembre, salaires, milliards, enseignement, exposition, publics, août, association, augmentation, théâtre, employés, avril, agriculture, budget, arts, académie, famille\n",
      "\n",
      "Thème 16 (Disours potentiel) : mme, madame, monsieur, fille, annoncer, août, meuse, décès, orchestre, namur, joseph, dem, prie, louer, musique, marie, concert, servante, auto, henri\n",
      "\n",
      "Thème 17 (Disours potentiel) : juin, mars, congo, idem, août, septembre, banque, cap, ind, novembre, avril, décembre, emp, actions, juillet, belg, vente, disponible, ord, février\n",
      "\n",
      "Thème 18 (Disours potentiel) : congrès, minute, course, match, chômeurs, bat, victoire, travailleurs, communistes, salaires, allocations, lea, équipe, louvain, vitesse, suisse, fonds, record, juillet, juin\n",
      "\n",
      "Thème 19 (Disours potentiel) : communiste, mars, populaire, britannique, communistes, front, partis, soviétique, travailleurs, avril, américain, procès, léopold, américaine, allemands, américains, sénat, province, témoin, bretagne\n",
      "\n",
      "Thème 20 (Disours potentiel) : tél, opel, neuf, cardinaux, renault, voiture, brux, auto, citroen, blanc, chevrolet, ford, choix, ath, royale, fiat, vente, austin, vend, luxe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel # Utilisation du modèle natif plus stable\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Paramètres (Ajustés selon les sources)\n",
    "# -------------------------------\n",
    "data_path = \"../../data/txt/\" \n",
    "# Les sources recommandent 280 thèmes pour une analyse fine [3]\n",
    "n_topics = 20 # Augmentez à 280 si vous avez un gros corpus\n",
    "n_top_words = 20 # Standard utilisé par les auteurs [6]\n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Chargement et Prétraitement\n",
    "# -------------------------------\n",
    "# Téléchargement des ressources françaises\n",
    "nltk.download('stopwords')\n",
    "# CRUCIAL : Utiliser le français pour l'Encyclopédie [1]\n",
    "stop_words = stopwords.words('french') \n",
    "\n",
    "def preprocess(text):\n",
    "    # Les auteurs recommandent de filtrer les mots fonctionnels [3]\n",
    "    return [token for token in simple_preprocess(text) if token not in stop_words and len(token) > 2]\n",
    "\n",
    "# Chargement (gestion des erreurs d'encodage fréquente sur les textes anciens)\n",
    "texts = []\n",
    "for f in sorted(os.listdir(data_path)):\n",
    "    if f.endswith(\".txt\"):\n",
    "        with open(os.path.join(data_path, f), \"r\", encoding=\"utf-8\", errors='ignore') as file:\n",
    "            texts.append(preprocess(file.read()))\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Création du dictionnaire et du modèle\n",
    "# -------------------------------\n",
    "dictionary = Dictionary(texts)\n",
    "# Filtrage : les auteurs excluent les mots trop fréquents ou rares [9]\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Entraînement du modèle LDA\n",
    "lda = LdaModel(corpus=corpus, num_topics=n_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Affichage (comparable aux Tables 1 & 2 des sources)\n",
    "# -------------------------------\n",
    "for topic_idx in range(n_topics):\n",
    "    # Récupération des 20 mots-clés [6]\n",
    "    words = lda.show_topic(topic_idx, topn=n_top_words)\n",
    "    topic_words = [word for word, prob in words]\n",
    "    print(f\"\\nThème {topic_idx + 1} (Disours potentiel) : {', '.join(topic_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9275c6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du corpus...\n",
      "Entraînement du modèle avec 10 thèmes...\n",
      "\n",
      "Thème 1 : doute, cent, surtout, donner, banque, produits, sait, grands, six, seul, etc, réunion, août, services, groupe, française, mai, ouvriers, semble, dix\n",
      "\n",
      "Thème 2 : britannique, sud, semble, voici, ouvriers, font, ensemble, août, grands, doivent, pourquoi, politiques, nombreux, février, américain, congrès, donner, chose, seul, anglais\n",
      "\n",
      "Thème 3 : côté, administration, occasion, sud, conditions, agit, arrêté, banque, services, régime, produits, grands, public, grandes, surtout, américains, police, internationale, groupe, petit\n",
      "\n",
      "Thème 4 : produits, etc, services, voix, groupe, mettre, française, sait, certaines, possible, intérêt, ouvriers, semble, grandes, public, britannique, main, dépenses, étrangères, mai\n",
      "\n",
      "Thème 5 : septembre, voici, services, américaine, grands, petit, dollars, pierre, police, ancien, tour, socialiste, moyen, mieux, souvent, public, reçu, personnel, réunion, étrangères\n",
      "\n",
      "Thème 6 : public, doute, dix, mettre, voix, banque, communistes, ensemble, bureau, peuvent, cent, dollars, septembre, française, ministère, femme, seul, libre, communiste, grands\n",
      "\n",
      "Thème 7 : mettre, jeune, six, régime, coup, pourquoi, petit, surtout, nombreux, cause, britannique, grands, occasion, cent, mal, septembre, anglais, française, tel, cour\n",
      "\n",
      "Thème 8 : produits, étrangères, donner, voici, voix, doivent, coup, britannique, août, aide, occasion, mieux, grands, grève, conditions, peuvent, six, aucune, jeune, mal\n",
      "\n",
      "Thème 9 : doute, cour, août, con, produits, aide, banque, grands, déclare, congrès, ministère, services, environ, liberté, septembre, intérêt, étrangères, donner, hier, ensemble\n",
      "\n",
      "Thème 10 : jeune, intérêt, cent, mme, personnes, banque, sens, ancien, réunion, américains, conditions, régime, mai, sud, augmentation, ensemble, ministère, moyen, doivent, fer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# -------------------------------\n",
    "# 1️⃣ Paramètres basés sur les sources\n",
    "# -------------------------------\n",
    "# Les auteurs ont testé 280, 300, 330 et 360 thèmes [1].\n",
    "# Ils ont conclu que le modèle à 280 thèmes était le plus cohérent [2].\n",
    "n_topics = 10\n",
    "# L'analyse repose sur les 20 mots les plus significatifs par thème [2].\n",
    "n_top_words = 20 \n",
    "\n",
    "# -------------------------------\n",
    "# 2️⃣ Chargement et Prétraitement\n",
    "# -------------------------------\n",
    "# Chemin vers votre fichier spécifique\n",
    "file_path = \"../../data/tmp/corpus_clean2.txt\"\n",
    "\n",
    "# Les sources soulignent l'importance des noms (substantifs) [3].\n",
    "# Pour simplifier, nous utilisons ici une suppression rigoureuse des stopwords.\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('french') # Crucial pour l'Encyclopédie [1, 4]\n",
    "\n",
    "def preprocess(text):\n",
    "    # Les auteurs filtrent les mots fonctionnels (stopwords) [1].\n",
    "    # Ils suggèrent de ne garder que les noms et noms propres [5].\n",
    "    tokens = simple_preprocess(text)\n",
    "    return [t for t in tokens if t not in stop_words and len(t) > 2]\n",
    "\n",
    "print(\"Chargement du corpus...\")\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    # On traite chaque ligne comme un article/document indépendant [6, 7].\n",
    "    processed_texts = [preprocess(line) for line in f]\n",
    "\n",
    "# -------------------------------\n",
    "# 3️⃣ Création du modèle (LDA)\n",
    "# -------------------------------\n",
    "# Création du dictionnaire et du format \"Bag of Words\" (sac de mots) [8].\n",
    "dictionary = Dictionary(processed_texts)\n",
    "# Filtrage des mots trop rares ou trop fréquents comme dans PhiloMine [7].\n",
    "#dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
    "\n",
    "print(f\"Entraînement du modèle avec {n_topics} thèmes...\")\n",
    "# Bien que les auteurs utilisent MALLET [1], le modèle LdaModel \n",
    "# de Gensim est une alternative moderne produisant des résultats comparables.\n",
    "lda = LdaModel(corpus=corpus, num_topics=n_topics, id2word=dictionary, passes=10)\n",
    "\n",
    "# -------------------------------\n",
    "# 4️⃣ Analyse des résultats\n",
    "# -------------------------------\n",
    "# Affichage des thèmes pour identifier les \"discours\" [2, 8].\n",
    "for topic_idx in range(n_topics):\n",
    "    words = lda.show_topic(topic_idx, topn=n_top_words)\n",
    "    topic_words = [word for word, prob in words]\n",
    "    print(f\"\\nThème {topic_idx + 1} : {', '.join(topic_words)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
