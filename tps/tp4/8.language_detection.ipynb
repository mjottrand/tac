{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La détection de langue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "987 TXT files found\n",
      "0 document(s) processed...\n",
      "50 document(s) processed...\n",
      "100 document(s) processed...\n",
      "150 document(s) processed...\n",
      "200 document(s) processed...\n",
      "250 document(s) processed...\n",
      "300 document(s) processed...\n",
      "350 document(s) processed...\n",
      "400 document(s) processed...\n",
      "450 document(s) processed...\n",
      "500 document(s) processed...\n",
      "550 document(s) processed...\n",
      "600 document(s) processed...\n",
      "650 document(s) processed...\n",
      "700 document(s) processed...\n",
      "750 document(s) processed...\n",
      "800 document(s) processed...\n",
      "850 document(s) processed...\n",
      "900 document(s) processed...\n",
      "950 document(s) processed...\n",
      "Done\n",
      "French\t987\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from langid.langid import LanguageIdentifier, model\n",
    "import pycountry\n",
    "\n",
    "\n",
    "identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
    "\n",
    "## Lister tous les documents\n",
    "root = \"../../data/txt/\"\n",
    "txts = os.listdir(root)\n",
    "print(f\"{len(txts)} TXT files found\")\n",
    "\n",
    "##détecter la langue sur tous les documents\n",
    "limit = None\n",
    "\n",
    "lang_dict = defaultdict(int)\n",
    "txts = sorted(txts)[:limit] if limit else txts\n",
    "\n",
    "for i, txt in enumerate(sorted(txts)):\n",
    "    if txt.endswith(\"txt\"):\n",
    "        if i % 50 == 0:\n",
    "            print(f'{i} document(s) processed...')\n",
    "        text = open(os.path.join(root, txt), \"r\", encoding=\"utf-8\").read()\n",
    "        text_length = len(text)\n",
    "        if text_length > 20:\n",
    "            lang, conf = identifier.classify(text)\n",
    "            lang_dict[lang] += 1\n",
    "        else:\n",
    "            print(f\"{txt} contains only {text_length} characters, treating as unknown\")\n",
    "            lang_dict['n/a'] += 1\n",
    "\n",
    "print(\"Done\")\n",
    "\n",
    "\n",
    "#Afficher le nombre de documents par langue\n",
    "\n",
    "for lang_code, nb_docs in lang_dict.items():\n",
    "    language = pycountry.languages.get(alpha_2=lang_code)\n",
    "    try:\n",
    "        lang_name = language.name\n",
    "    except AttributeError:\n",
    "        lang_name = language\n",
    "    print(f\"{lang_name}\\t{nb_docs}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
