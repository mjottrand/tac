{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction de Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraire les mots clés d'un document avec Yake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/LIAAD/yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     text = f.read()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Extraire les mots clés de ce texte  ← (TES LIGNES)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m keywords = \u001b[43mkw_extractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_keywords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m keywords  \u001b[38;5;66;03m# ← si tu veux l'afficher dans un notebook\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Ajouter uniquement les mots (pas les scores) dans le compteur global\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yake\\core\\yake.py:217\u001b[39m, in \u001b[36mKeywordExtractor.extract_keywords\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# Build features for single terms and multi-word terms\u001b[39;00m\n\u001b[32m    216\u001b[39m dc.build_single_terms_features(features=\u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m \u001b[43mdc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_mult_terms_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfeatures\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m# Collect and sort all valid candidates by score (lower is better)\u001b[39;00m\n\u001b[32m    220\u001b[39m result_set = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yake\\data\\core.py:464\u001b[39m, in \u001b[36mDataCore.build_mult_terms_features\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[33;03mBuild features for multi-word terms.\u001b[39;00m\n\u001b[32m    456\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    461\u001b[39m \u001b[33;03m    features (list, optional): List of features to build. If None, all available features will be built.\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# Update only valid candidates (filter then apply update_h)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m    465\u001b[39m     \u001b[38;5;28mmap\u001b[39m(\n\u001b[32m    466\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: x.update_h(features=features),\n\u001b[32m    467\u001b[39m         [cand \u001b[38;5;28;01mfor\u001b[39;00m cand \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.candidates.values() \u001b[38;5;28;01mif\u001b[39;00m cand.is_valid()],\n\u001b[32m    468\u001b[39m     )\n\u001b[32m    469\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yake\\data\\core.py:466\u001b[39m, in \u001b[36mDataCore.build_mult_terms_features.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[33;03mBuild features for multi-word terms.\u001b[39;00m\n\u001b[32m    456\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    461\u001b[39m \u001b[33;03m    features (list, optional): List of features to build. If None, all available features will be built.\u001b[39;00m\n\u001b[32m    462\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# Update only valid candidates (filter then apply update_h)\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m    465\u001b[39m     \u001b[38;5;28mmap\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    467\u001b[39m         [cand \u001b[38;5;28;01mfor\u001b[39;00m cand \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.candidates.values() \u001b[38;5;28;01mif\u001b[39;00m cand.is_valid()],\n\u001b[32m    468\u001b[39m     )\n\u001b[32m    469\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yake\\data\\composed_word.py:312\u001b[39m, in \u001b[36mComposedWord.update_h\u001b[39m\u001b[34m(self, features, is_virtual)\u001b[39m\n\u001b[32m    308\u001b[39m             features_cand.append(f_sum_prod)\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (features_cand, columns, seen)\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupdate_h\u001b[39m(\u001b[38;5;28mself\u001b[39m, features=\u001b[38;5;28;01mNone\u001b[39;00m, is_virtual=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    313\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    314\u001b[39m \u001b[33;03m    Update the term's score based on its constituent terms.\u001b[39;00m\n\u001b[32m    315\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    322\u001b[39m \u001b[33;03m        is_virtual (bool): Whether this is a virtual candidate not in text\u001b[39;00m\n\u001b[32m    323\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    324\u001b[39m     sum_h = \u001b[32m0.0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yake\n",
    "from collections import Counter\n",
    "\n",
    "# Instancier l'extracteur de mots clés\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"fr\", top=50)\n",
    "\n",
    "# Lister les fichiers .txt\n",
    "data_path = \"../../data/txt/\"\n",
    "files = [f for f in os.listdir(data_path) if f.endswith('.txt')]\n",
    "\n",
    "# Compteur global de mots clés\n",
    "keyword_counter = Counter()\n",
    "\n",
    "# Parcourir tous les fichiers\n",
    "for this_file in files:\n",
    "    file_path = os.path.join(data_path, this_file)\n",
    "\n",
    "    # Lire le texte du fichier\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Extraire les mots clés de ce texte  ← (TES LIGNES)\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    keywords  # ← si tu veux l'afficher dans un notebook\n",
    "\n",
    "    # Ajouter uniquement les mots (pas les scores) dans le compteur global\n",
    "    keyword_counter.update([kw for kw, score in keywords])\n",
    "\n",
    "# Récupérer les 100 mots clés les plus fréquents dans le corpus\n",
    "top_100_keywords = keyword_counter.most_common(100)\n",
    "\n",
    "top_100_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<yake.core.yake.KeywordExtractor at 0x24c0e52b090>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import yake\n",
    "\n",
    "\n",
    "# Instantier l'extracteur de mots clés\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"fr\", top=50)\n",
    "kw_extractor\n",
    "\n",
    "# Lister les Fichiers\n",
    "data_path = \"../../data/txt/\"\n",
    "files = [f for f in os.listdir(data_path) if f.endswith('.txt')]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "987"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimer le nombre de fichiers identifiés\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Récupérer le texte du fichier\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m text = \u001b[38;5;28mopen\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m).read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen ntpath>:147\u001b[39m, in \u001b[36mjoin\u001b[39m\u001b[34m(path, *paths)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen genericpath>:152\u001b[39m, in \u001b[36m_check_arg_types\u001b[39m\u001b[34m(funcname, *args)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: join() argument must be str, bytes, or os.PathLike object, not 'list'"
     ]
    }
   ],
   "source": [
    "# Récupérer le texte du fichier\n",
    "text = open(os.path.join(data_path, files), 'r', encoding='utf-8').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('heures', 0.004053388736617615),\n",
       " ('Belgique', 0.010107431329890188),\n",
       " ('Bruxelles', 0.01022252481445218),\n",
       " ('rue', 0.013638291056007801),\n",
       " ('juin', 0.015743691931778287),\n",
       " ('quintaux', 0.016228439133771578),\n",
       " ('Janvier', 0.020664632103466578),\n",
       " ('VAN COPPENOLLE', 0.021189940467665494),\n",
       " ('céréales', 0.02135155328271249),\n",
       " ('camions', 0.02137357971319409),\n",
       " ('Nat. Français', 0.024595064858240912),\n",
       " ('Français', 0.02509693412914364),\n",
       " ('millions', 0.02516478478228611),\n",
       " ('Juillet', 0.026743486666231685),\n",
       " ('EnA', 0.02715232894874067),\n",
       " ('Dimanche', 0.031196093639305145),\n",
       " (\"d'un\", 0.03249484627691108),\n",
       " ('plan Marshall', 0.0353756679753561),\n",
       " ('grande', 0.036923845121683),\n",
       " ('Samedi', 0.03701292104678005),\n",
       " ('Dernière Heure', 0.038309879355128834),\n",
       " ('chansons', 0.03988229298074696),\n",
       " ('maïs', 0.041253219763148906),\n",
       " ('céréales secondaires', 0.04362688497265421),\n",
       " ('quintaux métriques', 0.045112675869447526),\n",
       " (\"d'une\", 0.04530227365479261),\n",
       " ('ANCIENNE BELGIQUE', 0.04654755656228972),\n",
       " ('belge', 0.047301333046980365),\n",
       " ('heure', 0.04864066483941138),\n",
       " ('Concert', 0.04961646485873264),\n",
       " ('Bruxelles GEORGES BEATSE', 0.04984442559911342),\n",
       " (\"s'est\", 0.05210014604868351),\n",
       " (\"qu'il\", 0.05306270040700836),\n",
       " ('Brabant', 0.05324215917948585),\n",
       " ('direction', 0.05364989799152115),\n",
       " ('COPPENOLLE', 0.05416019663673532),\n",
       " ('DANSE', 0.054576389303399295),\n",
       " ('VAN', 0.05785228660308908),\n",
       " ('temps', 0.05881059296648513),\n",
       " ('plan', 0.05899943277083356),\n",
       " ('ans', 0.05942647880620315),\n",
       " ('Etats-Unis', 0.060876103735899204),\n",
       " ('cours', 0.0617754757307875),\n",
       " ('place', 0.06188770655708817),\n",
       " ('Bruxelles GEORGES', 0.0630188270893147),\n",
       " ('Namur', 0.06392912012727445),\n",
       " ('nuit', 0.06408389967299676),\n",
       " ('camionnettes', 0.0654323756216113),\n",
       " ('Arts', 0.06598535350420179),\n",
       " ('belges', 0.0662218662657725)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraire les mots clés de ce texte\n",
    "keywords = kw_extractor.extract_keywords(text)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VAN COPPENOLLE',\n",
       " 'Nat. Français',\n",
       " 'plan Marshall',\n",
       " 'Dernière Heure',\n",
       " 'céréales secondaires',\n",
       " 'quintaux métriques',\n",
       " 'ANCIENNE BELGIQUE',\n",
       " 'Bruxelles GEORGES']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ne garder que les bigrammes\n",
    "kept = []\n",
    "for kw, score in keywords:\n",
    "    words = kw.split()\n",
    "    if len(words) == 2:\n",
    "        kept.append(kw)\n",
    "kept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire la même opération sur tous les documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KB_JB1051_1947-02-01_01-00002.txt mentions these keywords: EDITH PIAF, marché noir, produits agricoles, BRUXELLES Edith, production agricole, môme Piaf...\n",
      "KB_JB1051_1947-02-18_01-00002.txt mentions these keywords: ai-je demandé, BBC Léger, Mardi Froid, mardis froids, Etudiants Communistes, production anglaise, osoEMSDagœ MARDI...\n",
      "KB_JB1051_1947-02-21_01-00001.txt mentions these keywords: Drapeau Rouge, général Franco, JOSEPH JACQUEMOTTE, Conférence Nationale, presse communiste, Affaires étrangères...\n",
      "KB_JB1051_1947-07-02_01-00003.txt mentions these keywords: pays européens, FERNAND JACQUEMOTTE, fraude fiscale, d'autre part, COMMISSION ECONOMIQUE, d'un programme, Commission d'assistance, programme général, d'autres pays...\n",
      "KB_JB1051_1947-07-24_01-00003.txt mentions these keywords: COP Jeudi, Libois demande, l'enseignement technique, ami rappelle, Faul Libois, ami Libois, demandons rai, l'enseignement officiel, cirer rsr...\n",
      "KB_JB1051_1947-08-27_01-00003.txt mentions these keywords: Parti Communiste, L'HEMISPHERE OCCIDENTAL, l'Amérique latine, Cour internationale, Nations Unies, prêt américain, pays Londres...\n",
      "KB_JB1051_1947-10-09_01-00001.txt mentions these keywords: BBUXELLES jjUPKONBS, Drapeau Rouge, L'Initiative Privée, PARTI COMMUNISTE, classes moyennes, parti fasciste...\n",
      "KB_JB1051_1947-12-01_01-00001.txt mentions these keywords: PARTI COMMUNISTE, EDGAR LALMAND, Comité Central, classe ouvrière, Parti fut, d'autre part, prix actuels, prix antérieurs, d'autres partis, d'une part, Benoit Frachon, PLAN MARSHALL, femmes communistes, ORGANE CENTRAL, Conférence Internationale...\n",
      "KB_JB1051_1948-01-03_01-00004.txt mentions these keywords: Rapid Vienne, CLASSES MOYENNES, travailleurs belges, Parti communiste, frontaliers belges, petits actionnaires, petits commerçants, classe ouvrière, masses laborieuses, D'autre part, ETE ECRASE, belges c'est, grandes équipes...\n",
      "KB_JB1051_1948-01-07_01-00003.txt mentions these keywords: parti communiste, partis démocratiques, gouvernement Schuman, front démocratique, plan Marshall, gouvernement français, partis communistes, gouvernement démocratique, partis réactionnaires, WALL STREET, réformes démocratiques, forces démocratiques, parti national, République populaire, communiste roumain...\n"
     ]
    }
   ],
   "source": [
    "for f in sorted(files)[:10]:\n",
    "    text = open(os.path.join(data_path, f), 'r', encoding=\"utf-8\").read()\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    kept = []\n",
    "    for kw, score in keywords:\n",
    "        words = kw.split()\n",
    "        if len(words) == 2:\n",
    "            kept.append(kw)\n",
    "    print(f\"{f} mentions these keywords: {', '.join(kept)}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cardinal Mercier', np.float64(0.005566539857736422)),\n",
       " ('janvier', np.float64(0.007353459282533203)),\n",
       " (\"qu'il\", np.float64(0.010527947157637062)),\n",
       " (\"D'UN AJOURNEMENT Londres\", np.float64(0.014704272743085013)),\n",
       " ('Paris', np.float64(0.017911419809381005)),\n",
       " ('cardinal', np.float64(0.019043765706252512)),\n",
       " ('rue', np.float64(0.019557148036767526)),\n",
       " ('justice', np.float64(0.02104948848292461)),\n",
       " ('Mercier', np.float64(0.021299178540643216)),\n",
       " ('exposition', np.float64(0.02217014330237372)),\n",
       " (\"d'une\", np.float64(0.022669704358927113)),\n",
       " (\"cardinal Mercier n'est\", np.float64(0.02432076150154022)),\n",
       " (\"D'UN\", np.float64(0.024546642404955365)),\n",
       " ('Coniérence du Désarmement', np.float64(0.02525723057475799)),\n",
       " ('Belgique', np.float64(0.025664938015230978)),\n",
       " (\"c'est\", np.float64(0.02666339652876907)),\n",
       " (\"jusqu'au\", np.float64(0.02700910881343268)),\n",
       " ('ViENT', np.float64(0.027830054012332454)),\n",
       " ('février', np.float64(0.029124611941075244)),\n",
       " ('Politique', np.float64(0.03094557841715115)),\n",
       " ('BELGE', np.float64(0.03444044761916593)),\n",
       " ('GOUVERNEMENT', np.float64(0.03451887463522327)),\n",
       " ('cardinal Mercier figure', np.float64(0.034751113791159124)),\n",
       " ('ministre', np.float64(0.03594794688174003)),\n",
       " ('francs', np.float64(0.03966658428827621)),\n",
       " (\"PARTISAN D'UN AJOURNEMENT\", np.float64(0.040378738573339026)),\n",
       " ('conférence', np.float64(0.041613843919836024)),\n",
       " ('Londres', np.float64(0.041663366622971765)),\n",
       " ('AJOURNEMENT Londres', np.float64(0.04487121619410376)),\n",
       " ('Japon', np.float64(0.04837389628612054)),\n",
       " ('hommes politiques', np.float64(0.049178138483801634)),\n",
       " ('Bruxelles', np.float64(0.049542984309391504)),\n",
       " ('Budget', np.float64(0.04982014748315793)),\n",
       " ('Galerie', np.float64(0.05009385281600769)),\n",
       " ('homme', np.float64(0.053587868183730625)),\n",
       " (\"N'EST\", np.float64(0.053631719943677984)),\n",
       " ('cardinal Mercier disparaît', np.float64(0.05431436026563686)),\n",
       " ('Havas', np.float64(0.05443997301187621)),\n",
       " ('Guerre', np.float64(0.05560031723428365)),\n",
       " ('vue', np.float64(0.05583261009067864)),\n",
       " (\"GOUVERNEMENT BRITANNIQUE N'EST\", np.float64(0.058153475713229354)),\n",
       " ('ETATS-UNIS', np.float64(0.059283952026267905)),\n",
       " ('février Paris', np.float64(0.060876202519563556)),\n",
       " ('GOUVERNEMENT BRITANNIQUE', np.float64(0.06282908002441372)),\n",
       " ('BAL', np.float64(0.06284111310849544)),\n",
       " ('hommes', np.float64(0.06430544182047675)),\n",
       " ('RELATIONS', np.float64(0.06450007481434132)),\n",
       " (\"D'UN AJOURNEMENT\", np.float64(0.06464879262824687)),\n",
       " ('Reuter', np.float64(0.06499658998335443)),\n",
       " ('Commission', np.float64(0.06557524801520069))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import yake\n",
    "\n",
    "# Instantier l'extracteur de mots clés\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"fr\", top=50)\n",
    "kw_extractor\n",
    "\n",
    "# Lister les Fichiers\n",
    "data_path = \"../data/txt/\"\n",
    "files = [f for f in os.listdir(data_path) if f.endswith('.txt')]\n",
    "\n",
    "# Lister les fichiers d'une année\n",
    "year = 1926\n",
    "files_1926=[f for f in files if str(year) in f]\n",
    "\n",
    "#Choisir un fichier\n",
    "\n",
    "files = files_1926[0]  # Premier fichier de l'année 1889\n",
    "text = open(os.path.join(data_path, files), 'r', encoding='utf-8').read()\n",
    "text[:500]  # Affiche les 500 premiers caractères\n",
    "\n",
    "# Extraire les mots clés\n",
    "keywords = kw_extractor.extract_keywords(text)\n",
    "keywords\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'files_1950' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Ne garder que les bigrammes pour l'année 1950\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mfiles_1950\u001b[49m):\n\u001b[32m      3\u001b[39m     text = \u001b[38;5;28mopen\u001b[39m(os.path.join(data_path, f), \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m).read()\n\u001b[32m      4\u001b[39m     keywords = kw_extractor.extract_keywords(text)\n",
      "\u001b[31mNameError\u001b[39m: name 'files_1950' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Ne garder que les bigrammes pour l'année 1950\n",
    "for f in sorted(files_1950):\n",
    "    text = open(os.path.join(data_path, f), 'r', encoding=\"utf-8\").read()\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    kept = []\n",
    "    for kw, score in keywords:\n",
    "        words = kw.split()\n",
    "        if len(words) == 2:\n",
    "            kept.append(kw)\n",
    "    print(f\"{f} mentions these keywords: {', '.join(kept)}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
