{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings : le modèle Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et traitement des phrases du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un objet qui *streame* les lignes d'un fichier pour économiser de la RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    \"\"\"Tokenize and Lemmatize sentences\"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename, encoding='utf-8', errors=\"backslashreplace\"):\n",
    "            yield [unidecode(w.lower()) for w in wordpunct_tokenize(line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = f\"../../data/sents.txt\"\n",
    "sentences = MySentences(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détection des bigrams\n",
    "\n",
    "Article intéressant sur le sujet : https://towardsdatascience.com/word2vec-for-phrases-learning-embeddings-for-more-than-one-word-727b6cf723cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phrases = Phrases(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bigram_phrases.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phraser = Phraser(phrases_model=bigram_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous répétons l'opération en envoyant cette fois la liste de bigrams afin d'extraire les trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_phrases = Phrases(bigram_phraser[sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_phraser = Phraser(phrases_model=trigram_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un corpus d'unigrams, bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(trigram_phraser[bigram_phraser[sentences]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement d'un premier modèle Word2Vec sur ce corpus (window = 5 ; min_count = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 25min 33s\n",
      "Wall time: 13min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=5, # La taille du \"contexte\", ici 5 mots avant et 5 après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus (on peut le mettre à plus avec un très gros corpus)\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauver le modèle dans un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = f\"../../data/tp3modèle1.model\"\n",
    "model.save(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorer le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger le modèle en mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../../data/tp3modèle1.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer la similarité entre deux termes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82690287"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"ministre\", \"gouvernement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23835611"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"bruxelles\", \"capitale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80381954"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"football\", \"sport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chercher les mots les plus proches d'un terme donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('efficacite', 0.8009935021400452),\n",
       " ('unite', 0.7881107330322266),\n",
       " ('action', 0.7860397100448608),\n",
       " ('habilete', 0.7850760221481323),\n",
       " ('economie', 0.7823023796081543),\n",
       " ('armature', 0.7791286110877991),\n",
       " ('hypocrisie', 0.7789782881736755),\n",
       " ('ingratitude', 0.7773498892784119),\n",
       " ('faiblesse', 0.7729592323303223),\n",
       " ('indifference', 0.7712991833686829)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"energie\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('principaute', 0.9286186695098877),\n",
       " ('colonie_belge', 0.8750392198562622),\n",
       " ('peninsule', 0.8721823692321777),\n",
       " ('legion_etrangere', 0.8436046838760376),\n",
       " ('crete', 0.8430392146110535),\n",
       " ('section_belge', 0.8391808271408081),\n",
       " ('region_parisienne', 0.8371219635009766),\n",
       " ('famille_royale', 0.8368630409240723),\n",
       " ('rhenanie', 0.8297626376152039),\n",
       " ('mer_rouge', 0.828758716583252)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"capitale\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guerro', 0.8601323366165161),\n",
       " ('demobilisation', 0.850451648235321),\n",
       " ('communaute', 0.8402085900306702),\n",
       " ('ruhr', 0.8351300954818726),\n",
       " ('guorre', 0.8123477101325989),\n",
       " ('nation', 0.81203693151474),\n",
       " ('collectivite', 0.8118950724601746),\n",
       " ('marine_marchande', 0.8092591762542725),\n",
       " ('cession', 0.8083475232124329),\n",
       " ('mobilisation', 0.8056179881095886)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"colonie\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire des recherches complexes à travers l'espace vectoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rallye', 0.8309959173202515), ('ski', 0.8088762760162354), ('marathon', 0.8018616437911987), ('lotus', 0.7980955243110657), ('club', 0.7963196039199829), ('championnat_interclubs', 0.7806680202484131), ('patinage', 0.7763028740882874), ('motocyclisme', 0.7757370471954346), ('challenge', 0.7700577974319458), ('criterium_national', 0.7673411965370178)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['sport', 'cyclisme'], negative=['football']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dechargement', 0.774098813533783), ('ciment', 0.765225887298584), ('vapeur', 0.753138542175293), ('chargement', 0.7297610640525818), ('wagon', 0.7174645662307739), ('reservoir', 0.7160706520080566), ('oharbon', 0.7151058912277222), ('metal', 0.7108349800109863), ('plancher', 0.710391640663147), ('benzol', 0.7100170254707336)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['petrole', 'charbon'], negative=['economie']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rome', 0.8768160939216614), ('berlin', 0.8662904500961304), ('moscou', 0.8549507260322571), ('vienne', 0.8375968933105469), ('pekin', 0.8286409378051758), ('budapest', 0.8105076551437378), ('tokio', 0.8054363131523132), ('teheran', 0.7997197508811951), ('madrid', 0.7921528220176697), ('ankara', 0.7884011268615723)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['paris', 'londres'], negative=['bruxelles']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Exploration Modèle numéro 2 (window = 10 ; min_count = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainer, sauver et charger le modèle 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 28min 32s\n",
      "Wall time: 14min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=10, # La taille du \"contexte\", ici 5 mots avant et 5 après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus (on peut le mettre à plus avec un très gros corpus)\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = f\"../../data/tp3modèle2.model\"\n",
    "model.save(outfile)\n",
    "\n",
    "model = Word2Vec.load(\"../../data/tp3modèle2.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la similarité entre deux termes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83393437"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"ministre\", \"gouvernement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1894651"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"bruxelles\", \"capitale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8331728"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"football\", \"sport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chercher les mots les plus proches d'un terme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('action', 0.8092068433761597),\n",
       " ('impuissance', 0.8056376576423645),\n",
       " ('vigueur', 0.790776789188385),\n",
       " ('inertie', 0.7804978489875793),\n",
       " ('indifference', 0.7786954641342163),\n",
       " ('faiblesse', 0.7742382287979126),\n",
       " ('ignorance', 0.7718334794044495),\n",
       " ('efficacite', 0.7699581384658813),\n",
       " ('inutilite', 0.7671987414360046),\n",
       " ('exces', 0.7646012902259827)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"energie\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('principaute', 0.9032148122787476),\n",
       " ('peninsule', 0.8321616053581238),\n",
       " ('vieille_cite', 0.8222121000289917),\n",
       " ('colonie_belge', 0.8157285451889038),\n",
       " ('crete', 0.8121602535247803),\n",
       " ('cite_ardente', 0.8106663823127747),\n",
       " ('population', 0.8001872301101685),\n",
       " ('banlieue', 0.7910217046737671),\n",
       " ('baltique', 0.7852566242218018),\n",
       " ('sicile', 0.7839754819869995)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"capitale\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cession', 0.7881654500961304),\n",
       " ('communaute', 0.7801764011383057),\n",
       " ('guerro', 0.7788991332054138),\n",
       " ('caisse_autonome', 0.7747275829315186),\n",
       " ('guerre', 0.7741776704788208),\n",
       " ('collectivite', 0.7708531618118286),\n",
       " ('nation', 0.7698078155517578),\n",
       " ('marine_marchande', 0.7647090554237366),\n",
       " ('dotation', 0.761199414730072),\n",
       " ('large_mesure', 0.7594324946403503)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"colonie\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire des recherches complexes à travers l'espace vectoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rallye', 0.8378145098686218), ('patinage', 0.8234587907791138), ('automobilisme', 0.8085893392562866), ('ski', 0.7935338020324707), ('club', 0.7926409244537354), ('motocyclisme', 0.7887585759162903), ('marathon', 0.7879200577735901), ('championnat_national', 0.7843747735023499), ('tennis', 0.7824083566665649), ('derby', 0.7809351086616516)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['sport', 'cyclisme'], negative=['football']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ciment', 0.7813999652862549), ('chargement', 0.7581973075866699), ('rails', 0.742189884185791), ('dechargement', 0.7404050230979919), ('vapeur', 0.7351729869842529), ('dragueur', 0.7305387854576111), ('wagon', 0.7304143309593201), ('coke', 0.7244198322296143), ('terril', 0.7223315834999084), ('bris', 0.7195336818695068)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['petrole', 'charbon'], negative=['economie']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('berlin', 0.8634778261184692), ('rome', 0.8586385846138), ('moscou', 0.8540712594985962), ('vienne', 0.8101162910461426), ('pekin', 0.8076951503753662), ('teheran', 0.7905494570732117), ('tokio', 0.790129542350769), ('ankara', 0.7840481400489807), ('madrid', 0.783541738986969), ('francfort', 0.7780991196632385)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['paris', 'londres'], negative=['bruxelles']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Exploration Modèle numéro 3 (window = 5 ; min_count = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainer, sauver et charger le modèle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 23min 9s\n",
      "Wall time: 12min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=5, # La taille du \"contexte\", ici 5 mots avant et 5 après le mot observé\n",
    "    min_count=10, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus (on peut le mettre à plus avec un très gros corpus)\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = f\"../../data/tp3modèle3.model\"\n",
    "model.save(outfile)\n",
    "\n",
    "model = Word2Vec.load(\"../../data/tp3modèle3.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la similarité entre deux termes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82124734"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"ministre\", \"gouvernement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26588836"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"bruxelles\", \"capitale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7862419"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"football\", \"sport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chercher les mots les plus proches d'un terme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('efficacite', 0.8085280656814575),\n",
       " ('indifference', 0.8056556582450867),\n",
       " ('habilete', 0.7931762337684631),\n",
       " ('indulgence', 0.7835987210273743),\n",
       " ('faiblesse', 0.7818674445152283),\n",
       " ('ignorance', 0.7805702686309814),\n",
       " ('exces', 0.7800633311271667),\n",
       " ('hostilite', 0.778734564781189),\n",
       " ('avarice', 0.7771517038345337),\n",
       " ('action', 0.7739158272743225)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"energie\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('principaute', 0.895905077457428),\n",
       " ('peninsule', 0.8709556460380554),\n",
       " ('colonie_belge', 0.8617537021636963),\n",
       " ('region_parisienne', 0.8493494987487793),\n",
       " ('population', 0.8359257578849792),\n",
       " ('rhenanie', 0.8349437117576599),\n",
       " ('crete', 0.8326060771942139),\n",
       " ('mediterranee', 0.8311338424682617),\n",
       " ('ville', 0.8289176225662231),\n",
       " ('vieille_cite', 0.8239152431488037)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"capitale\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guerro', 0.8581104874610901),\n",
       " ('ruhr', 0.8544015288352966),\n",
       " ('communaute', 0.8507928252220154),\n",
       " ('marine_marchande', 0.8395102620124817),\n",
       " ('collectivite', 0.8279435634613037),\n",
       " ('guerre', 0.8265326023101807),\n",
       " ('nation', 0.8237548470497131),\n",
       " ('guorre', 0.8217140436172485),\n",
       " ('demobilisation', 0.8211349248886108),\n",
       " ('decentralisation', 0.8162907958030701)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"colonie\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire des recherches complexes à travers l'espace vectoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rallye', 0.8566862940788269), ('marathon', 0.8264356851577759), ('patinage', 0.811134397983551), ('motocross', 0.8025138974189758), ('club', 0.7957391142845154), ('ski', 0.7812719345092773), ('championnat_national', 0.7808427214622498), ('derby', 0.776512622833252), ('golf', 0.7736311554908752), ('festival', 0.7704788446426392)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['sport', 'cyclisme'], negative=['football']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ciment', 0.7966238260269165), ('naphte', 0.760569155216217), ('dechargement', 0.7577843070030212), ('gravier', 0.7463268637657166), ('groenland', 0.7358078956604004), ('genievre', 0.730974555015564), ('foin', 0.7282389998435974), ('silex', 0.7197476625442505), ('vapeur', 0.7187607288360596), ('chargement', 0.7146559953689575)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['petrole', 'charbon'], negative=['economie']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rome', 0.8686522841453552), ('berlin', 0.8626545667648315), ('moscou', 0.8578198552131653), ('budapest', 0.849730908870697), ('tokio', 0.8311203718185425), ('vienne', 0.815719723701477), ('stockholm', 0.7930417060852051), ('pekin', 0.7902159094810486), ('teheran', 0.7872359752655029), ('madrid', 0.786888599395752)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['paris', 'londres'], negative=['bruxelles']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
