{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings : le modèle Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et traitement des phrases du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un objet qui *streame* les lignes d'un fichier pour économiser de la RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    \"\"\"Tokenize and Lemmatize sentences\"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in open(self.filename, encoding='utf-8', errors=\"backslashreplace\"):\n",
    "            yield [unidecode(w.lower()) for w in wordpunct_tokenize(line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = f\"../../data/sents.txt\"\n",
    "sentences = MySentences(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détection des bigrams\n",
    "\n",
    "Article intéressant sur le sujet : https://towardsdatascience.com/word2vec-for-phrases-learning-embeddings-for-more-than-one-word-727b6cf723cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phrases = Phrases(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bigram_phrases.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phraser = Phraser(phrases_model=bigram_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous répétons l'opération en envoyant cette fois la liste de bigrams afin d'extraire les trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_phrases = Phrases(bigram_phraser[sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_phraser = Phraser(phrases_model=trigram_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un corpus d'unigrams, bigrams, trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(trigram_phraser[bigram_phraser[sentences]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement d'un premier modèle Word2Vec sur ce corpus (window = 5 ; min_count = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 24min 46s\n",
      "Wall time: 13min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=5, # La taille du \"contexte\", ici 5 mots avant et 5 après le mot observé\n",
    "    min_count=5, # On ignore les mots qui n'apparaissent pas au moins 5 fois dans le corpus (on peut le mettre à plus avec un très gros corpus)\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauver le modèle dans un fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = f\"../../data/tp3modèle1.model\"\n",
    "model.save(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorer le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charger le modèle en mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"../../data/tp3modèle1.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer la similarité entre deux termes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6530492"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28434867"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"bruxelles\", \"capitale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7751446"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"football\", \"sport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chercher les mots les plus proches d'un terme donné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('efficacite', 0.8020390272140503),\n",
       " ('ignorance', 0.794345498085022),\n",
       " ('abnegation', 0.7877367734909058),\n",
       " ('exces', 0.7864693999290466),\n",
       " ('impuissance', 0.7857227325439453),\n",
       " ('inertie', 0.785113513469696),\n",
       " ('habilete', 0.7830312848091125),\n",
       " ('indifference', 0.7785846590995789),\n",
       " ('action', 0.7782384157180786),\n",
       " ('indulgence', 0.7774134874343872)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"energie\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('principaute', 0.8992559313774109),\n",
       " ('peninsule', 0.8890219330787659),\n",
       " ('mecque', 0.8710858225822449),\n",
       " ('colonie_belge', 0.86016446352005),\n",
       " ('crete', 0.8509145379066467),\n",
       " ('mer_rouge', 0.8480837941169739),\n",
       " ('region_parisienne', 0.8446575403213501),\n",
       " ('ville', 0.8353541493415833),\n",
       " ('rhenanie', 0.8318886160850525),\n",
       " ('ruhr', 0.8301903605461121)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"capitale\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guerro', 0.8754188418388367),\n",
       " ('marine_marchande', 0.8579181432723999),\n",
       " ('ruhr', 0.8459063172340393),\n",
       " ('communaute', 0.8456894159317017),\n",
       " ('guerre', 0.8295210003852844),\n",
       " ('collectivite', 0.82573002576828),\n",
       " ('demobilisation', 0.8230893611907959),\n",
       " ('nation', 0.8143597841262817),\n",
       " ('prohibition', 0.8128385543823242),\n",
       " ('rhenanie', 0.8122228384017944)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"colonie\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire des recherches complexes à travers l'espace vectoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rallye', 0.8281869888305664), ('club', 0.8214699029922485), ('ski', 0.8057788610458374), ('bridge', 0.7888575792312622), ('golf', 0.7766138911247253), ('marathon', 0.7751936316490173), ('motocyclisme', 0.7718915939331055), ('patinage', 0.7684836983680725), ('festival', 0.767212450504303), ('automobilisme', 0.7575165033340454)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['sport', 'cyclisme'], negative=['football']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ciment', 0.7864272594451904), ('bris', 0.7456074953079224), ('dechargement', 0.7232266068458557), ('bois', 0.7160535454750061), ('rail', 0.7079124450683594), ('gravier', 0.707025408744812), ('coke', 0.7046268582344055), ('pignon', 0.7007346749305725), ('reservoir', 0.7006763219833374), ('puits', 0.7004013061523438)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['petrole', 'charbon'], negative=['economie']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('berlin', 0.8665355443954468), ('moscou', 0.863474428653717), ('rome', 0.8593438267707825), ('budapest', 0.821623682975769), ('vienne', 0.8211926221847534), ('tokio', 0.8130141496658325), ('pekin', 0.8039390444755554), ('teheran', 0.7862898111343384), ('stockholm', 0.7855962514877319), ('madrid', 0.7807698845863342)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['paris', 'londres'], negative=['bruxelles']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Exploration Modèle numéro 2 (window = 5 ; min_count = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainer, sauver et charger le modèle 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 23min 21s\n",
      "Wall time: 14min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=5, # La taille du \"contexte\", ici 5 mots avant et 5 après le mot observé\n",
    "    min_count=25, # On ignore les mots qui n'apparaissent pas au moins 25 fois dans le corpus (on peut le mettre à plus avec un très gros corpus)\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = f\"../../data/tp3modèle2.model\"\n",
    "model.save(outfile)\n",
    "\n",
    "model = Word2Vec.load(\"../../data/tp3modèle2.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la similarité entre deux termes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5857733"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24837849"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"bruxelles\", \"capitale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631886"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"football\", \"sport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chercher les mots les plus proches d'un terme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('efficacite', 0.8164990544319153),\n",
       " ('imprecision', 0.7957242131233215),\n",
       " ('habilete', 0.7945934534072876),\n",
       " ('impetuosite', 0.786982536315918),\n",
       " ('action', 0.7868802547454834),\n",
       " ('obstination', 0.7846607565879822),\n",
       " ('atome', 0.7793523669242859),\n",
       " ('agressivite', 0.778461217880249),\n",
       " ('indifference', 0.7738246917724609),\n",
       " ('avarice', 0.7710710167884827)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"energie\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('principaute', 0.9143218994140625),\n",
       " ('colonie_belge', 0.8777433037757874),\n",
       " ('peninsule', 0.8536405563354492),\n",
       " ('region', 0.8454762697219849),\n",
       " ('region_parisienne', 0.8452200889587402),\n",
       " ('crete', 0.8390171527862549),\n",
       " ('ruhr', 0.8371900320053101),\n",
       " ('population', 0.8371796607971191),\n",
       " ('mer_rouge', 0.8345614075660706),\n",
       " ('ville', 0.8335004448890686)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"capitale\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guerro', 0.8351351618766785),\n",
       " ('communaute', 0.8318026065826416),\n",
       " ('recherche_scientifique', 0.8177210688591003),\n",
       " ('population', 0.8173548579216003),\n",
       " ('nation', 0.8164836764335632),\n",
       " ('marine_marchande', 0.8137192726135254),\n",
       " ('ruhr', 0.8076481819152832),\n",
       " ('sarre', 0.8048380613327026),\n",
       " ('collectivite', 0.804188072681427),\n",
       " ('decentralisation', 0.802216112613678)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"colonie\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire des recherches complexes à travers l'espace vectoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rallye', 0.8030558228492737), ('ski', 0.7991294860839844), ('patinage', 0.7675231099128723), ('club', 0.7660090923309326), ('festival_international', 0.7624330520629883), ('touriste', 0.7603012323379517), ('marathon', 0.7564849853515625), ('bridge', 0.75617516040802), ('lotus', 0.7492101192474365), ('motocyclisme', 0.7474668622016907)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['sport', 'cyclisme'], negative=['football']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ciment', 0.8163164854049683), ('dechargement', 0.7656125426292419), ('vapeur', 0.7519423961639404), ('metal', 0.73738032579422), ('plancher', 0.7354918718338013), ('jambon', 0.7318801283836365), ('puits', 0.7134420871734619), ('goulot', 0.7128924131393433), ('reservoir', 0.7123075723648071), ('gaz_naturel', 0.708698570728302)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['petrole', 'charbon'], negative=['economie']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rome', 0.8769578337669373), ('moscou', 0.8763126730918884), ('berlin', 0.8735169768333435), ('tokio', 0.8544323444366455), ('budapest', 0.8541219830513), ('vienne', 0.848977267742157), ('teheran', 0.8438239693641663), ('pekin', 0.8349310159683228), ('beyrouth', 0.8215287923812866), ('ankara', 0.8096815943717957)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['paris', 'londres'], negative=['bruxelles']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Exploration Modèle numéro 3 (window = 15 ; min_count = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainer, sauver et charger le modèle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 26min 32s\n",
      "Wall time: 13min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(\n",
    "    corpus, # On passe le corpus de ngrams que nous venons de créer\n",
    "    vector_size=32, # Le nombre de dimensions dans lesquelles le contexte des mots devra être réduit, aka. vector_size\n",
    "    window=15, # La taille du \"contexte\", ici 15 mots avant et 15 après le mot observé\n",
    "    min_count=10, # On ignore les mots qui n'apparaissent pas au moins 10 fois dans le corpus (on peut le mettre à plus avec un très gros corpus)\n",
    "    workers=4, # Permet de paralléliser l'entraînement du modèle en 4 threads\n",
    "    epochs=5 # Nombre d'itérations du réseau de neurones sur le jeu de données pour ajuster les paramètres avec la descente de gradient, aka. epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = f\"../../data/tp3modèle3.model\"\n",
    "model.save(outfile)\n",
    "\n",
    "model = Word2Vec.load(\"../../data/tp3modèle3.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la similarité entre deux termes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60208446"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"homme\", \"femme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.165795"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"bruxelles\", \"capitale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77865374"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"football\", \"sport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chercher les mots les plus proches d'un terme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('faiblesse', 0.8286552429199219),\n",
       " ('vigueur', 0.8121653199195862),\n",
       " ('inutilite', 0.7910152077674866),\n",
       " ('force', 0.7889838218688965),\n",
       " ('inertie', 0.787100613117218),\n",
       " ('apathie', 0.7767216563224792),\n",
       " ('action', 0.7766621708869934),\n",
       " ('impuissance', 0.7761543989181519),\n",
       " ('organisation_sociale', 0.77167809009552),\n",
       " ('vitalite', 0.7690632343292236)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"energie\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('principaute', 0.8655822277069092),\n",
       " ('colonie_belge', 0.7873440980911255),\n",
       " ('peninsule', 0.7849032282829285),\n",
       " ('contree', 0.7683951258659363),\n",
       " ('peripherie', 0.7673091888427734),\n",
       " ('region', 0.7616746425628662),\n",
       " ('liaison_avec', 0.7574202418327332),\n",
       " ('partie_occidentale', 0.7543638348579407),\n",
       " ('banlieue', 0.7537333965301514),\n",
       " ('population', 0.7529217600822449)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"capitale\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('marine_marchande', 0.7861441373825073),\n",
       " ('corporation', 0.7816519737243652),\n",
       " ('transaction', 0.7761610150337219),\n",
       " ('cession', 0.7638018131256104),\n",
       " ('demobilisation', 0.7574828863143921),\n",
       " ('collectivite', 0.7505149245262146),\n",
       " ('recherche_scientifique', 0.746623694896698),\n",
       " ('caisse_autonome', 0.745442807674408),\n",
       " ('wehrmacht', 0.7453480958938599),\n",
       " ('priorite_absolue', 0.7437680959701538)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"colonie\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire des recherches complexes à travers l'espace vectoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rallye', 0.808153510093689), ('club', 0.8042554259300232), ('olub', 0.7906923294067383), ('annuelle_epreuve', 0.7674909830093384), ('coupe', 0.7663635015487671), ('ciub', 0.7620835900306702), ('trophee', 0.7611589431762695), ('motocross', 0.7581794261932373), ('challenge', 0.756144106388092), ('automobilisme', 0.748543381690979)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['sport', 'cyclisme'], negative=['football']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dechargement', 0.7855389714241028), ('chargement', 0.7737162113189697), ('wagon', 0.7684531807899475), ('naphte', 0.7533102631568909), ('ciment', 0.7505702972412109), ('puits', 0.7452909350395203), ('dragueur', 0.7449766993522644), ('mouillage', 0.7402570247650146), ('port', 0.7354591488838196), ('coke', 0.7289832830429077)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['petrole', 'charbon'], negative=['economie']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('moscou', 0.8732405304908752), ('berlin', 0.8701534867286682), ('rome', 0.8568610548973083), ('vienne', 0.8105735778808594), ('madrid', 0.80129075050354), ('aux_indes', 0.7861269116401672), ('washington', 0.7822923064231873), ('geneve', 0.7786237001419067), ('tokio', 0.7748748660087585), ('ankara', 0.774321436882019)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['paris', 'londres'], negative=['bruxelles']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
