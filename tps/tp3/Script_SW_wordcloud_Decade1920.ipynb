{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuages de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports et stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords (Idem que dans s1)\n",
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"les\", \"plus\", \"cette\", \"fait\", \"faire\", \"être\", \"deux\", \"comme\", \"dont\", \"tout\",\n",
    "       \"ils\", \"bien\", \"sans\", \"peut\", \"tous\", \"après\", \"ainsi\", \"donc\", \"cet\", \"sous\",\n",
    "       \"celle\", \"entre\", \"encore\", \"toutes\", \"pendant\", \"moins\", \"dire\", \"cela\", \"non\",\n",
    "       \"faut\", \"trois\", \"aussi\", \"dit\", \"avoir\", \"doit\", \"contre\", \"depuis\", \"autres\",\n",
    "       \"van\", \"het\", \"autre\", \"jusqu\", \"ville\", \"rossel\", \"dem\", \"rue\", \"prix\", \"maison\", \n",
    "       \"an\", \"agence\", \"louer\",\"très\", \"vendre\", \"bon\", \"heure\", \"place\", \"demande\", \"ecr\", \n",
    "       \"francs\", \"grand\", \"midi\", \"état\", \"vend\", \"belle\", \"ruo\", \"avenue\", \"brux\", \"nord\",\n",
    "       \"fille\", \"gaz\", \"bonne\", \"adr\", \"vente\",  \"etc\", \"neuf\", \"bon\", \"libre\", \"mod\", \n",
    "       \"jours\", \"mois\", \"salle\", \"chambre\", \"eau\", \"app\", \"dés\", \"près\", \"grand\", \"grande\", \n",
    "       \"un\", \"une\", \"tél\", \"occasion\", \"matin\", \"soir\", \"beau\", \"on\", \"auto\", \"tout\", \"toute\",\n",
    "       \"bail\", \"avant\", \"après\", \"jeune\", \"vieux\", \"disp\", \"belge\", \"belgique\", \"cuis\", \"villa\",\n",
    "       \"cour\", \"notaire\", \"cours\", \"bel\",\"pers\", \"bureau\", \"quart\", \"pays\", \"suite\", \"cap\", \"peu\", \n",
    "       \"situation\", \"garage\", \"mai\", \"gros\", \"rossel\", \"ros\", \"chez\", \"centre\", \"lundi\", \"mardi\", \n",
    "       \"mercredi\", \"jeudi\", \"vendredi\", \"samedi\", \"dimanche\",  \"fer\", \"mr\", \"mme\", \"hôtel\", \"jardin\", \n",
    "       \"jard\", \"gar\", \"porte\", \"garni\", \"pension\", \"bain\", \"bons\", \"jour\", \"écrire\", \"ans\", \"part\", \n",
    "       \"ecrire\", \"heures\", \"janvier\", \"lieu\", \"dame\", \"par\", \"rez\", \"adresser\", \"loyer\", \"meuble\", \n",
    "       \"meubles\", \"bons\", \"pet\", \"plusieurs\", \"neuve\", \"achat\", \"mén\", \"temps\", \"trav\", \"sér\", \n",
    "       \"mètres\", \"lux\", \"vue\", \"réf\", \"ord\", \"aven\", \"cherche\", \"sal\", \"aveo\", \"dos\", \"ler\",\"offre\", \n",
    "       \"petit\", \"petits\", \"petites\", \"lib\", \"lit\", \"enf\", \"fem\", \"téléphone\", \"SIT\", \"faç\", \"env\", \n",
    "       \"cher\",\"jeu\", \"jn\", \"jne\", \"cause\", \"mari\", \"quelques\", \"quelque\", \"masmoment\", \"salon\", \n",
    "       \"chambre\", \"chambres\", \"celui\", \"celle\", \"lui\", \"ont\", \"été\", \"vers\", \"pour\", \"or\", \"ni\", \n",
    "       \"car\", \"mais\", \"où\", \"et\", \"enfin\", \"enfants\", \"femme\", \"appart\", \"lot\", \"lots\", \"céder\", \n",
    "       \"prés\", \"ordre\", \"bois\", \"Bruxelles\", \"Louise\", \"bruxelles\", \"chaussée\", \"français\", \"conf\", \"saint\", \"travail\"]\n",
    "sw = set(sw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer un fichier contenant le texte de tous les journaux d'une année donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir une décennie\n",
    "year = 1926\n",
    "\n",
    "# Lister les fichiers de cette année\n",
    "data_path = '../data'\n",
    "txt_path = '../../data/txt'\n",
    "txts = [f for f in os.listdir(txt_path) if os.path.isfile(os.path.join(txt_path, f)) and str(year) in f]\n",
    "len(txts)\n",
    "\n",
    "# Stocker le contenu de ces fichiers dans une liste\n",
    "content_list = []\n",
    "for txt in txts:\n",
    "    with open(os.path.join(txt_path, txt), 'r', encoding='utf-8') as f:\n",
    "        content_list.append(f.read())\n",
    "\n",
    "# Compter le nombre d'éléments (=fichiers) dans la liste\n",
    "len(content_list)\n",
    "\n",
    "# Imprimer les 200 premiers caractères du contenu du premier fichier\n",
    "content_list[0][0:200]\n",
    "\n",
    "# Ecrire tout le contenu dans un fichier temporaire\n",
    "temp_path = '../../data/tmp'\n",
    "if not os.path.exists(temp_path):\n",
    "    os.mkdir(temp_path)\n",
    "with open(os.path.join(temp_path, f'{year}.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write(' '.join(content_list))\n",
    "\n",
    "    # Imprimer le contenu du fichier et constater les \"déchets\"\n",
    "with open(os.path.join(temp_path, f'{year}.txt'), 'r', encoding='utf-8') as f:\n",
    "    before = f.read()\n",
    "\n",
    "before[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyer le fichier à l'aide d'une fonction de nettoyage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer la fonction de nettoyage (à adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(year, folder=None):\n",
    "    if folder is None:\n",
    "        input_path = f\"{year}.txt\"\n",
    "        output_path = f\"{year}_clean.txt\"\n",
    "    else:\n",
    "        input_path = f\"{folder}/{year}.txt\"\n",
    "        output_path = f\"{folder}/{year}_clean.txt\"\n",
    "    output = open(output_path, \"w\", encoding='utf-8')\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        words = nltk.wordpunct_tokenize(text)\n",
    "        kept = [w.upper() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "        kept_string = \" \".join(kept)\n",
    "        output.write(kept_string)\n",
    "    return f'Output has been written in {output_path}!'\n",
    "\n",
    "#Appliquer la fonction sur le fichier complet de l'année\n",
    "clean_text(year, folder=temp_path)\n",
    "\n",
    "# Vérifier le résultat\n",
    "with open(os.path.join(temp_path, f'{year}_clean.txt'), 'r', encoding='utf-8') as f:\n",
    "    after = f.read()\n",
    "\n",
    "after[:500]\n",
    "\n",
    "#Nuage de mots\n",
    "##Afficher les termes les plus fréquents\n",
    "\n",
    "frequencies = Counter(after.split())\n",
    "print(frequencies.most_common(100))\n",
    "\n",
    "##Créer, stocker et affocher le nuage de mots\n",
    "cloud = WordCloud(width=2000, height=1000, background_color='white').generate_from_frequencies(frequencies)\n",
    "cloud.to_file(os.path.join(temp_path, f\"{year}.png\"))\n",
    "Image(filename=os.path.join(temp_path, f\"{year}.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
